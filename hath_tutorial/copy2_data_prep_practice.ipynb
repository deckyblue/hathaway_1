{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#PLOTTING\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "#STATS\n",
    "import scipy.stats as stats\n",
    "\n",
    "#the following line prevents pandas from giving unecessary errors \n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have saved the data file into a different folder than your current working directory (i.e., where you saved this python script), you'll need to change your working directory to where you saved the data \n",
    "\n",
    "Using the second line of code, change '..\\\\PhD_data\\\\BHO7' to wherever you saved the file (you'll have to change the slashes if you are not using windows)\n",
    "\n",
    "Or if this python script and the data file are saved in the same location, comment out the second line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check current working directory\n",
    "os.getcwd()\n",
    "\n",
    "#change working directory\n",
    "# os.chdir('..\\\\PhD_data\\\\BH07') \n",
    "\n",
    "###we had a lot of trouble changing the working directory \n",
    "###skipped bc unnecessary to code\n",
    "os.chdir('C:\\\\Users\\\\dexte\\\\hathaway_1\\\\data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load in our data! \n",
    "\n",
    "I've given you a datafile with two sessions (session 29 and 30), so that the code will run relatively quickly.\n",
    "\n",
    "Normally, we would be loading in a lot more data.\n",
    "\n",
    "For this experiment, there are two groups - transgene positive rats (experimental) and transgene negative rats (control)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we need to set a few variables for loading in the data - these will change depending on the dataset\n",
    "\n",
    "#we are just loading in data from one file, but we could load data in from multiple files and combine them\n",
    "file_names = ['BH07_raw_free_S29-30.xlsx']\n",
    "##file_names is a List[str], where the strings are file names\n",
    "##free indicates free choice (they get to choose from 4 options)\n",
    "##free is after the forced choice training which forces exploration\n",
    "\n",
    "group_names = ['Tg negative','Tg positive'] #control and experimental group, respectively\n",
    "\n",
    "title = 'Nigrostriatal activation during acquisition' #title for figures, describing the experiment\n",
    "startsess = 29 #first session in this dataset\n",
    "endsess = 30 #last session in this dataset\n",
    "\n",
    "\n",
    "#the following two lines of code assign the rat subject numbers to the experimental and control group lists\n",
    "#you may notice there is no subject 10 - she died earlier in the experiment :( \n",
    "exp_group = [1, 2, 7, 8, 11, 12, 16, 19, 20, 21, 22, 25, 26, 29, 32] #Tg positive\n",
    "\n",
    "control_group = [3, 4, 5, 6, 9, 13, 14, 15, 17, 18, 23, 24, 27, 28, 30, 31] #Tg negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(fnames): \n",
    "    for i, file in enumerate(fnames): \n",
    "        if i == 0:\n",
    "            df = pd.read_excel(fnames[i])\n",
    "        else:\n",
    "            df2 = pd.read_excel(fnames[i])\n",
    "            df = df.append(df2, ignore_index = True)\n",
    "        return df\n",
    "\n",
    "df = load_data(file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSN</th>\n",
       "      <th>StartDate</th>\n",
       "      <th>StartTime</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Group</th>\n",
       "      <th>Box</th>\n",
       "      <th>Experiment</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Session</th>\n",
       "      <th>Trial</th>\n",
       "      <th>...</th>\n",
       "      <th>Pun_Persev_H5</th>\n",
       "      <th>Pun_HeadEntry</th>\n",
       "      <th>Pun_Dur</th>\n",
       "      <th>Premature_Resp</th>\n",
       "      <th>Premature_Hole</th>\n",
       "      <th>Rew_Persev_H1</th>\n",
       "      <th>Rew_Persev_H2</th>\n",
       "      <th>Rew_Persev_H3</th>\n",
       "      <th>Rew_Persev_H4</th>\n",
       "      <th>Rew_Persev_H5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rGT_A-cue</td>\n",
       "      <td>2020-10-09</td>\n",
       "      <td>11:01:00</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rGT_A-cue</td>\n",
       "      <td>2020-10-09</td>\n",
       "      <td>11:01:00</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29</td>\n",
       "      <td>2.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rGT_A-cue</td>\n",
       "      <td>2020-10-09</td>\n",
       "      <td>11:01:00</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rGT_A-cue</td>\n",
       "      <td>2020-10-09</td>\n",
       "      <td>11:01:00</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rGT_A-cue</td>\n",
       "      <td>2020-10-09</td>\n",
       "      <td>11:01:00</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         MSN  StartDate StartTime  Subject  Group  Box  Experiment  Comment  \\\n",
       "0  rGT_A-cue 2020-10-09  11:01:00       25    0.0    1         0.0      NaN   \n",
       "1  rGT_A-cue 2020-10-09  11:01:00       25    0.0    1         0.0      NaN   \n",
       "2  rGT_A-cue 2020-10-09  11:01:00       25    0.0    1         0.0      NaN   \n",
       "3  rGT_A-cue 2020-10-09  11:01:00       25    0.0    1         0.0      NaN   \n",
       "4  rGT_A-cue 2020-10-09  11:01:00       25    0.0    1         0.0      NaN   \n",
       "\n",
       "   Session  Trial  ...  Pun_Persev_H5  Pun_HeadEntry  Pun_Dur  Premature_Resp  \\\n",
       "0       29    1.0  ...              3              3       30               0   \n",
       "1       29    2.1  ...              0              0        0               1   \n",
       "2       29    2.0  ...              3              2       30               0   \n",
       "3       29    3.0  ...              0              0        0               0   \n",
       "4       29    4.0  ...              2              2       30               0   \n",
       "\n",
       "   Premature_Hole  Rew_Persev_H1  Rew_Persev_H2  Rew_Persev_H3  Rew_Persev_H4  \\\n",
       "0               0              0              0              0              0   \n",
       "1               5              0              0              0              0   \n",
       "2               0              0              0              0              0   \n",
       "3               0              0              0              0              0   \n",
       "4               0              0              0              0              0   \n",
       "\n",
       "   Rew_Persev_H5  \n",
       "0              0  \n",
       "1              0  \n",
       "2              0  \n",
       "3              0  \n",
       "4              0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's check the top few lines of the dataframe\n",
    "\n",
    "df.head()\n",
    "\n",
    "#it should look the same as the excel file \n",
    "##note, df contains the raw dataframe!\n",
    "##note the ... (some columns aren't being shown, like \"Chosen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine our data!\n",
    "\n",
    "The following function will give us a summary of the session numbers +  session dates for each rat (subject), plus the number of trials they did for each session (the rightmost column) \n",
    "\n",
    "This gives us a quick way to see if there are any missing or incorrect session numbers\n",
    "\n",
    "Session numbers are typed in manually by the experimenter each day, so mistakes definitely happen :) \n",
    "\n",
    "We can also check to make sure that all the original data we want from MED-PC was exported into the excel file that we loaded in - sometimes one or two will get missed \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject  StartDate   Session\n",
      "1        2020-10-09  29         131.1\n",
      "         2020-10-10  30         124.0\n",
      "2        2020-10-09  29          76.1\n",
      "         2020-10-10  30          81.0\n",
      "3        2020-10-09  29          49.0\n",
      "         2020-10-10  30          45.0\n",
      "4        2020-10-09  29         103.0\n",
      "         2020-10-10  30          97.0\n",
      "5        2020-10-09  29          68.1\n",
      "         2020-10-10  30          69.0\n",
      "6        2020-10-09  29          88.0\n",
      "         2020-10-10  30          75.0\n",
      "7        2020-10-09  28          53.0\n",
      "         2020-10-10  29          65.0\n",
      "         2020-10-13  30          56.1\n",
      "8        2020-10-09  29         124.0\n",
      "         2020-10-10  30         121.0\n",
      "9        2020-10-09  29          62.0\n",
      "         2020-10-10  30          61.0\n",
      "11       2020-10-09  29         132.0\n",
      "         2020-10-10  30         136.1\n",
      "12       2020-10-09  29          54.0\n",
      "         2020-10-10  30          72.0\n",
      "13       2020-10-09  29          67.0\n",
      "         2020-10-10  30          60.0\n",
      "14       2020-10-09  29          80.1\n",
      "         2020-10-10  30          91.0\n",
      "15       2020-10-09  29          54.0\n",
      "         2020-10-10  30          60.1\n",
      "16       2020-10-09  29          57.0\n",
      "         2020-10-10  30          59.1\n",
      "17       2020-10-09  28          63.1\n",
      "         2020-10-10  29          43.1\n",
      "         2020-10-13  30          73.0\n",
      "18       2020-10-09  29          76.0\n",
      "         2020-10-10  30          69.0\n",
      "19       2020-10-09  29          72.0\n",
      "         2020-10-10  30          76.0\n",
      "20       2020-10-09  29         107.1\n",
      "         2020-10-10  30         109.0\n",
      "21       2020-10-09  29          70.0\n",
      "         2020-10-10  30          74.0\n",
      "22       2020-10-09  28         121.0\n",
      "         2020-10-10  29         115.0\n",
      "         2020-10-13  30          88.0\n",
      "23       2020-10-09  29          90.0\n",
      "         2020-10-10  30         107.1\n",
      "24       2020-10-09  29         114.0\n",
      "         2020-10-10  30         117.0\n",
      "25       2020-10-09  29          66.0\n",
      "         2020-10-10  30          65.0\n",
      "26       2020-10-09  29          75.1\n",
      "         2020-10-10  30          61.1\n",
      "27       2020-10-09  29          84.0\n",
      "         2020-10-10  30          95.0\n",
      "28       2020-10-09  29          81.0\n",
      "         2020-10-10  30          91.1\n",
      "29       2020-10-09  29          79.0\n",
      "         2020-10-10  30          72.0\n",
      "30       2020-10-09  29         125.0\n",
      "         2020-10-10  30         129.0\n",
      "31       2020-10-09  29          55.0\n",
      "         2020-10-10  30          90.0\n",
      "32       2020-10-09  29          75.0\n",
      "         2020-10-10  30          81.0\n",
      "Name: Trial, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def check_sessions(df): \n",
    "    pd.set_option('display.max_rows', None)\n",
    "    print(df.groupby(['Subject', 'StartDate', 'Session'])['Trial'].max())\n",
    "    pd.set_option('display.max_rows', df.Subject.max())\n",
    "    \n",
    "check_sessions(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def drop_sessions(df, session_num):\n",
    "#     drop_sess = list(df.loc[df['Session'] == session_num].index)\n",
    "#     df.drop(drop_sess, inplace = True)\n",
    "#     df.reset_index(inplace = True)\n",
    "\n",
    "# drop_sessions(df, 28)\n",
    "\n",
    "def drop_sessions(df, session_nums):\n",
    "    'Takes in a list of session numbers, and removes the data from specified session numbers'\n",
    "    for s in session_nums:\n",
    "        drop_sess = list(df.loc[df['Session'] == s].index)\n",
    "        df.drop(drop_sess, inplace = True)\n",
    "        df.reset_index(inplace = True)\n",
    "    return None ##could replace with check_sessions(df)\n",
    "\n",
    "drop_sessions(df, [28])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject  StartDate   Session\n",
      "1        2020-10-09  29         131.1\n",
      "         2020-10-10  30         124.0\n",
      "2        2020-10-09  29          76.1\n",
      "         2020-10-10  30          81.0\n",
      "3        2020-10-09  29          49.0\n",
      "         2020-10-10  30          45.0\n",
      "4        2020-10-09  29         103.0\n",
      "         2020-10-10  30          97.0\n",
      "5        2020-10-09  29          68.1\n",
      "         2020-10-10  30          69.0\n",
      "6        2020-10-09  29          88.0\n",
      "         2020-10-10  30          75.0\n",
      "7        2020-10-10  29          65.0\n",
      "         2020-10-13  30          56.1\n",
      "8        2020-10-09  29         124.0\n",
      "         2020-10-10  30         121.0\n",
      "9        2020-10-09  29          62.0\n",
      "         2020-10-10  30          61.0\n",
      "11       2020-10-09  29         132.0\n",
      "         2020-10-10  30         136.1\n",
      "12       2020-10-09  29          54.0\n",
      "         2020-10-10  30          72.0\n",
      "13       2020-10-09  29          67.0\n",
      "         2020-10-10  30          60.0\n",
      "14       2020-10-09  29          80.1\n",
      "         2020-10-10  30          91.0\n",
      "15       2020-10-09  29          54.0\n",
      "         2020-10-10  30          60.1\n",
      "16       2020-10-09  29          57.0\n",
      "         2020-10-10  30          59.1\n",
      "17       2020-10-10  29          43.1\n",
      "         2020-10-13  30          73.0\n",
      "18       2020-10-09  29          76.0\n",
      "         2020-10-10  30          69.0\n",
      "19       2020-10-09  29          72.0\n",
      "         2020-10-10  30          76.0\n",
      "20       2020-10-09  29         107.1\n",
      "         2020-10-10  30         109.0\n",
      "21       2020-10-09  29          70.0\n",
      "         2020-10-10  30          74.0\n",
      "22       2020-10-10  29         115.0\n",
      "         2020-10-13  30          88.0\n",
      "23       2020-10-09  29          90.0\n",
      "         2020-10-10  30         107.1\n",
      "24       2020-10-09  29         114.0\n",
      "         2020-10-10  30         117.0\n",
      "25       2020-10-09  29          66.0\n",
      "         2020-10-10  30          65.0\n",
      "26       2020-10-09  29          75.1\n",
      "         2020-10-10  30          61.1\n",
      "27       2020-10-09  29          84.0\n",
      "         2020-10-10  30          95.0\n",
      "28       2020-10-09  29          81.0\n",
      "         2020-10-10  30          91.1\n",
      "29       2020-10-09  29          79.0\n",
      "         2020-10-10  30          72.0\n",
      "30       2020-10-09  29         125.0\n",
      "         2020-10-10  30         129.0\n",
      "31       2020-10-09  29          55.0\n",
      "         2020-10-10  30          90.0\n",
      "32       2020-10-09  29          75.0\n",
      "         2020-10-10  30          81.0\n",
      "Name: Trial, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#let's recheck the dataframe session numbers - you will see that each rat now only has two sessions\n",
    "\n",
    "check_sessions(df)\n",
    "##check_sessions body indicates it will only print \"Subject\", \"StartDate\" and \"Session\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've loaded in our data, the first thing we need to do is create an options column that specifies whether the rats chose P1, P2, P3 or P4, instead of the hole number (which is stored in the 'Chosen' column)\n",
    "\n",
    "We need to make sure that we account for version A and version B\n",
    "\n",
    "We can do this by referencing the MSN column in the dataframe. \n",
    "MSN stands for 'MED-STATE NOTATION' which is the language that MEDPC programs are written in. \n",
    "You can think of MSN as the task name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['rGT_A-cue', 'rGT_B-cue'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['MSN'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>MSN</th>\n",
       "      <th>StartDate</th>\n",
       "      <th>StartTime</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Group</th>\n",
       "      <th>Box</th>\n",
       "      <th>Experiment</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Session</th>\n",
       "      <th>...</th>\n",
       "      <th>Pun_HeadEntry</th>\n",
       "      <th>Pun_Dur</th>\n",
       "      <th>Premature_Resp</th>\n",
       "      <th>Premature_Hole</th>\n",
       "      <th>Rew_Persev_H1</th>\n",
       "      <th>Rew_Persev_H2</th>\n",
       "      <th>Rew_Persev_H3</th>\n",
       "      <th>Rew_Persev_H4</th>\n",
       "      <th>Rew_Persev_H5</th>\n",
       "      <th>option</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>rGT_A-cue</td>\n",
       "      <td>2020-10-09</td>\n",
       "      <td>11:01:00</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>rGT_A-cue</td>\n",
       "      <td>2020-10-09</td>\n",
       "      <td>11:01:00</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>rGT_A-cue</td>\n",
       "      <td>2020-10-09</td>\n",
       "      <td>11:01:00</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>rGT_A-cue</td>\n",
       "      <td>2020-10-09</td>\n",
       "      <td>11:01:00</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>rGT_A-cue</td>\n",
       "      <td>2020-10-09</td>\n",
       "      <td>11:01:00</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6201</th>\n",
       "      <td>6515</td>\n",
       "      <td>rGT_B-cue</td>\n",
       "      <td>2020-10-10</td>\n",
       "      <td>11:29:57</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6202</th>\n",
       "      <td>6516</td>\n",
       "      <td>rGT_B-cue</td>\n",
       "      <td>2020-10-10</td>\n",
       "      <td>11:29:57</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6203</th>\n",
       "      <td>6517</td>\n",
       "      <td>rGT_B-cue</td>\n",
       "      <td>2020-10-10</td>\n",
       "      <td>11:29:57</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6204</th>\n",
       "      <td>6518</td>\n",
       "      <td>rGT_B-cue</td>\n",
       "      <td>2020-10-10</td>\n",
       "      <td>11:29:57</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6205</th>\n",
       "      <td>6519</td>\n",
       "      <td>rGT_B-cue</td>\n",
       "      <td>2020-10-10</td>\n",
       "      <td>11:29:57</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6206 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index        MSN  StartDate StartTime  Subject  Group  Box  Experiment  \\\n",
       "0         0  rGT_A-cue 2020-10-09  11:01:00       25    0.0    1         0.0   \n",
       "1         1  rGT_A-cue 2020-10-09  11:01:00       25    0.0    1         0.0   \n",
       "2         2  rGT_A-cue 2020-10-09  11:01:00       25    0.0    1         0.0   \n",
       "3         3  rGT_A-cue 2020-10-09  11:01:00       25    0.0    1         0.0   \n",
       "4         4  rGT_A-cue 2020-10-09  11:01:00       25    0.0    1         0.0   \n",
       "...     ...        ...        ...       ...      ...    ...  ...         ...   \n",
       "6201   6515  rGT_B-cue 2020-10-10  11:29:57       32    NaN    5         NaN   \n",
       "6202   6516  rGT_B-cue 2020-10-10  11:29:57       32    NaN    5         NaN   \n",
       "6203   6517  rGT_B-cue 2020-10-10  11:29:57       32    NaN    5         NaN   \n",
       "6204   6518  rGT_B-cue 2020-10-10  11:29:57       32    NaN    5         NaN   \n",
       "6205   6519  rGT_B-cue 2020-10-10  11:29:57       32    NaN    5         NaN   \n",
       "\n",
       "      Comment  Session  ...  Pun_HeadEntry  Pun_Dur  Premature_Resp  \\\n",
       "0         NaN       29  ...              3       30               0   \n",
       "1         NaN       29  ...              0        0               1   \n",
       "2         NaN       29  ...              2       30               0   \n",
       "3         NaN       29  ...              0        0               0   \n",
       "4         NaN       29  ...              2       30               0   \n",
       "...       ...      ...  ...            ...      ...             ...   \n",
       "6201      NaN       30  ...              0        0               0   \n",
       "6202      NaN       30  ...              0        0               0   \n",
       "6203      NaN       30  ...              0       10               0   \n",
       "6204      NaN       30  ...              0       40               0   \n",
       "6205      NaN       30  ...              1       40               0   \n",
       "\n",
       "      Premature_Hole  Rew_Persev_H1  Rew_Persev_H2  Rew_Persev_H3  \\\n",
       "0                  0              0              0              0   \n",
       "1                  5              0              0              0   \n",
       "2                  0              0              0              0   \n",
       "3                  0              0              0              0   \n",
       "4                  0              0              0              0   \n",
       "...              ...            ...            ...            ...   \n",
       "6201               0              0              0              0   \n",
       "6202               0              0              0              0   \n",
       "6203               0              0              0              0   \n",
       "6204               0              0              0              0   \n",
       "6205               0              0              0              0   \n",
       "\n",
       "      Rew_Persev_H4  Rew_Persev_H5  option  \n",
       "0                 0              0       3  \n",
       "1                 0              0       0  \n",
       "2                 0              0       3  \n",
       "3                 0              0       3  \n",
       "4                 0              0       3  \n",
       "...             ...            ...     ...  \n",
       "6201              0              0       0  \n",
       "6202              0              0       0  \n",
       "6203              0              0       2  \n",
       "6204              0              0       4  \n",
       "6205              0              0       4  \n",
       "\n",
       "[6206 rows x 32 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this function sets up an option column with correct P1 to P4 configuration for version A and B\n",
    "def get_choices(df):\n",
    "    configA = np.array([1, 4, 0, 2, 3]) #this is the order for version A - i.e., hole 1 corresponds to P1\n",
    "    configB = np.array([4, 1, 0, 3, 2]) #this is the order for version B - i.e., hole 1 corresponds to P4\n",
    "\n",
    "    df['option'] = df['MSN'].str.contains(\"B\").values*configB[df['Chosen'].astype('int').ravel()-1].astype('int') + \\\n",
    "        df['MSN'].str.contains(\"A\").values*configA[df['Chosen'].astype('int').ravel()-1].astype('int')\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        if df['Chosen'][i] == 0:\n",
    "            df['option'][i] = 0\n",
    "    return df\n",
    "\n",
    "df = get_choices(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       3\n",
       "1       0\n",
       "2       3\n",
       "3       3\n",
       "4       3\n",
       "       ..\n",
       "6201    0\n",
       "6202    0\n",
       "6203    2\n",
       "6204    4\n",
       "6205    4\n",
       "Name: option, Length: 6206, dtype: int32"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['option']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know the P1 to P4 choice of each rat, we need to summarize this choice by converting it to a percentage\n",
    "\n",
    "I.e., what is the percentage choice of each option for each rat, for each session?\n",
    "\n",
    "The code for this is two different functions; the first can calculate the percentage choice for P1-P4 for a single session.\n",
    "The second function uses the first one to calculate the %choice for all sessions\n",
    "\n",
    "Note: this is by far the slowest function in this script, so I'm hoping to optimize in the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>29P1</th>\n",
       "      <th>29P2</th>\n",
       "      <th>29P3</th>\n",
       "      <th>29P4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90.8397</td>\n",
       "      <td>0</td>\n",
       "      <td>8.39695</td>\n",
       "      <td>0.763359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.33333</td>\n",
       "      <td>65.3333</td>\n",
       "      <td>10.6667</td>\n",
       "      <td>14.6667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.17391</td>\n",
       "      <td>8.69565</td>\n",
       "      <td>56.5217</td>\n",
       "      <td>32.6087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.88235</td>\n",
       "      <td>73.5294</td>\n",
       "      <td>4.90196</td>\n",
       "      <td>15.6863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1.53846</td>\n",
       "      <td>98.4615</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.5</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>27.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.07692</td>\n",
       "      <td>10.7692</td>\n",
       "      <td>64.6154</td>\n",
       "      <td>21.5385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.41935</td>\n",
       "      <td>92.7419</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>4.03226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.27869</td>\n",
       "      <td>3.27869</td>\n",
       "      <td>90.1639</td>\n",
       "      <td>3.27869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10.687</td>\n",
       "      <td>88.5496</td>\n",
       "      <td>0.763359</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>18.5185</td>\n",
       "      <td>42.5926</td>\n",
       "      <td>0</td>\n",
       "      <td>38.8889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7.8125</td>\n",
       "      <td>28.125</td>\n",
       "      <td>60.9375</td>\n",
       "      <td>3.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.5</td>\n",
       "      <td>55</td>\n",
       "      <td>40</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.04082</td>\n",
       "      <td>20.4082</td>\n",
       "      <td>69.3878</td>\n",
       "      <td>8.16327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>14.0351</td>\n",
       "      <td>21.0526</td>\n",
       "      <td>10.5263</td>\n",
       "      <td>54.386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8.10811</td>\n",
       "      <td>37.8378</td>\n",
       "      <td>48.6486</td>\n",
       "      <td>5.40541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4.05405</td>\n",
       "      <td>68.9189</td>\n",
       "      <td>27.027</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19.4444</td>\n",
       "      <td>30.5556</td>\n",
       "      <td>38.8889</td>\n",
       "      <td>11.1111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.94175</td>\n",
       "      <td>94.1748</td>\n",
       "      <td>1.94175</td>\n",
       "      <td>1.94175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>27.2727</td>\n",
       "      <td>31.8182</td>\n",
       "      <td>18.1818</td>\n",
       "      <td>22.7273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4.38596</td>\n",
       "      <td>82.4561</td>\n",
       "      <td>4.38596</td>\n",
       "      <td>8.77193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>7.77778</td>\n",
       "      <td>78.8889</td>\n",
       "      <td>7.77778</td>\n",
       "      <td>5.55556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>9.90099</td>\n",
       "      <td>72.2772</td>\n",
       "      <td>11.8812</td>\n",
       "      <td>5.94059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>12.1622</td>\n",
       "      <td>58.1081</td>\n",
       "      <td>5.40541</td>\n",
       "      <td>24.3243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>18.2927</td>\n",
       "      <td>48.7805</td>\n",
       "      <td>19.5122</td>\n",
       "      <td>13.4146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>10.3896</td>\n",
       "      <td>64.9351</td>\n",
       "      <td>2.5974</td>\n",
       "      <td>22.0779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>26.5823</td>\n",
       "      <td>10.1266</td>\n",
       "      <td>53.1646</td>\n",
       "      <td>10.1266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>7.27273</td>\n",
       "      <td>83.6364</td>\n",
       "      <td>3.63636</td>\n",
       "      <td>5.45455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0</td>\n",
       "      <td>47.619</td>\n",
       "      <td>7.93651</td>\n",
       "      <td>44.4444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       29P1     29P2      29P3      29P4\n",
       "1   90.8397        0   8.39695  0.763359\n",
       "2   9.33333  65.3333   10.6667   14.6667\n",
       "3   2.17391  8.69565   56.5217   32.6087\n",
       "4   5.88235  73.5294   4.90196   15.6863\n",
       "5         0  1.53846   98.4615         0\n",
       "6       2.5       70         0      27.5\n",
       "7   3.07692  10.7692   64.6154   21.5385\n",
       "8   2.41935  92.7419  0.806452   4.03226\n",
       "9   3.27869  3.27869   90.1639   3.27869\n",
       "11   10.687  88.5496  0.763359         0\n",
       "12  18.5185  42.5926         0   38.8889\n",
       "13   7.8125   28.125   60.9375     3.125\n",
       "14      2.5       55        40       2.5\n",
       "15  2.04082  20.4082   69.3878   8.16327\n",
       "16  14.0351  21.0526   10.5263    54.386\n",
       "17  8.10811  37.8378   48.6486   5.40541\n",
       "18  4.05405  68.9189    27.027         0\n",
       "19  19.4444  30.5556   38.8889   11.1111\n",
       "20  1.94175  94.1748   1.94175   1.94175\n",
       "21  27.2727  31.8182   18.1818   22.7273\n",
       "22  4.38596  82.4561   4.38596   8.77193\n",
       "23  7.77778  78.8889   7.77778   5.55556\n",
       "24  9.90099  72.2772   11.8812   5.94059\n",
       "25        0        0       100         0\n",
       "26  12.1622  58.1081   5.40541   24.3243\n",
       "27  18.2927  48.7805   19.5122   13.4146\n",
       "28  10.3896  64.9351    2.5974   22.0779\n",
       "29  26.5823  10.1266   53.1646   10.1266\n",
       "30        0      100         0         0\n",
       "31  7.27273  83.6364   3.63636   5.45455\n",
       "32        0   47.619   7.93651   44.4444"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_sum_choice(num, df): \n",
    "    df1 = df.loc[df['Session'] == num]\n",
    "    \n",
    "    subs = df1.Subject.unique()\n",
    "    subs.sort()\n",
    "    percentage = pd.DataFrame(columns = [str(num) + 'P1', str(num) + 'P2', str(num) + 'P3', str(num) + 'P4'])\n",
    "    \n",
    "    for sub in subs: \n",
    "        for i, column in enumerate(percentage.columns): \n",
    "            percentage.at[sub, column] = (len(df1.loc[(df1.option == i + 1) & ##P1 is 1 in the option column\n",
    "                                            (df1.Subject == sub)]))/(len(df1.loc[(df1['option'] != 0) & \n",
    "                                                                                (df.Subject == sub)])) *100\n",
    "    return percentage\n",
    "    \n",
    "    \n",
    "num = 29\n",
    "# df1 = df.loc[df['Session'] == 29]\n",
    "# subs = df1.Subject.unique()\n",
    "# subs.sort()\n",
    "# subs\n",
    "percentage = pd.DataFrame(columns = [str(num) + 'P1', str(num) + 'P2', str(num) + 'P3', str(num) + 'P4'])\n",
    "percentage\n",
    "\n",
    "df_summary = get_sum_choice(29, df)\n",
    "df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All objects passed were None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-d33b8d9716d2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m#let's try it out!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mdf_summary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_sum_choice_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[0mdf_summary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-d33b8d9716d2>\u001b[0m in \u001b[0;36mget_sum_choice_all\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m##recall, get_sum_choice outputs a dataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mdf1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_sess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m###appends the list of dataframes side by side\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[1;31m#let's also calculate the risk score for each session - (P1 + P2) - (P3 + P4)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mnum\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Session'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    272\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIndexes\u001b[0m \u001b[0mhave\u001b[0m \u001b[0moverlapping\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'a'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m     \"\"\"\n\u001b[1;32m--> 274\u001b[1;33m     op = _Concatenator(\n\u001b[0m\u001b[0;32m    275\u001b[0m         \u001b[0mobjs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m         \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 349\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"All objects passed were None\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    350\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m         \u001b[1;31m# consolidate data & figure out what our result ndim is going to be\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: All objects passed were None"
     ]
    }
   ],
   "source": [
    "#now let's do it for all sessions - in this case 29 and 30\n",
    "def get_sum_choice_all(df):\n",
    "    #create an empty list to store the sessions individually\n",
    "    df_sess = []\n",
    "    for num in np.sort(df['Session'].unique()): ##for each session number in list of session numbers \n",
    "        df_sess.append(get_sum_choice(num,df)) ##append the summary info from get_sum_choice to the above list ###appending side-to-side? ####just makes a list\n",
    "    #then turn that list into a df\n",
    "    ##recall, get_sum_choice outputs a dataframe\n",
    "\n",
    "    df1 = pd.concat(df_sess, axis=1) ###appends the list of dataframes side by side\n",
    "    #let's also calculate the risk score for each session - (P1 + P2) - (P3 + P4)\n",
    "    for num in np.sort(df['Session'].unique()):\n",
    "        df1['risk'+ str(num)] = df1[str(num)+'P1'] + df1[str(num)+'P2']- df1[str(num)+'P3'] - df1[str(num)+'P4']\n",
    "        ##these are all names of columns \n",
    "        ##df1[str(num)+'P2'] is 29P2\n",
    "    return df1\n",
    "\n",
    "##feedback: make an object for np.sort(df['Session'].unique()) --> nit-picky!\n",
    "##note: df1[\"column_name\"] gets that column\n",
    "\n",
    "#let's try it out! \n",
    "df_summary = get_sum_choice_all(df)\n",
    "df_summary\n",
    "\n",
    "##feedback: strange that the variable df, and the object df are used interchangeably "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK! Now that we have our choice data summarized, we can move on to the other variables - thankfully much more straightforward haha\n",
    "\n",
    "First let's do percentage of premature responses. To calculate this, we need to sum up the total number of premature responses for each rat, and divide by the number of trials initiated (so premature trials and completed trials are both in the denominator).\n",
    "- ##both in the denominator, therefore, we must count the .1's as well for trials initiated\n",
    "\n",
    "From this point forward, we will be appending all subsequent variables to the df_summary we created above\n",
    "\n",
    "So we need to pass both the raw data (df) and the summary data (df_summary) to each function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract premature response percentages from raw dataframe, and append it to the summary df\n",
    "def get_premature(df_raw,df_sum):\n",
    "    #add up the number of premature responses made by (each subject for each session)--> the group\n",
    "    #save this information to a dataframe called prem_resp\n",
    "    prem_resp = df_raw.groupby(['Subject', 'Session'],as_index=False)['Premature_Resp'].sum()\n",
    "\n",
    "##prem_resp took the raw df, grouped by subject and session, and summed the premature responses --> made a df\n",
    "    \n",
    "    #calculate the number of initiated trials for each subject for each session \n",
    "    prem_resp['Trials'] = df_raw.groupby(['Subject','Session'],as_index=False)['Trial'].count()['Trial']\n",
    "    ##makes a new column called 'Trials' which counts the # of trials initiated\n",
    "    ##'Trial' is an existing column in the raw df (in the .xlsx file)\n",
    "    ###why is there 2 'Trial'? #### just takes the trials - try a new cell \n",
    "\n",
    "    #calculate the premature percent by dividing # of premature responses by # of trials initiated, times 100    \n",
    "    prem_resp['prem_percent'] = prem_resp['Premature_Resp']/prem_resp['Trials'] * 100\n",
    "    ###can we say this in English? easy\n",
    "\n",
    "    #add this information to the summary dataframe\n",
    "    #the column name will be 'prem' + session number - i.e., prem29 for session 29\n",
    "    for num in np.sort(df_raw['Session'].unique()): #for each session in the raw dataframe\n",
    "        #for that session, extract the prem_percent column from prem_resp and add it to the summary dataframe\n",
    "        #set the index as the subject number, so it matches the summary dataframe\n",
    "        df_sum['prem' + str(num)] = prem_resp.loc[prem_resp['Session']==num].set_index('Subject')['prem_percent']\n",
    "        ####locate session == num, set index to Subject (1-32), and call prem_percent column of prem_resp --> assign it to df_sum(yadayada)\n",
    "    return df_sum\n",
    "\n",
    "#let's try it out!\n",
    "df_summary = get_premature(df, df_summary)\n",
    "df_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's calculate our latencies! This is even simpler than premature responding because we don't need to calculate any additional information - we only need to find the mean value for each rat and session\n",
    "\n",
    "The following function calculates the mean choice latency and mean collect latency for each rat and each session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latencies(df_raw,df_sum):\n",
    "    #extract only completed trials (including non-completed trials will skew the mean, as the latency is zero for those trials)\n",
    "    df_raw = df_raw.loc[df_raw['Chosen'] != 0] ##'Chosen' = 0 indicates a prem_response or omission\n",
    "    #group by subject and session, then calculate the mean collect latency\n",
    "    collect_lat = df_raw.groupby(['Subject','Session'],as_index=False)['Collect_Lat'].mean()\n",
    "    #group by subject and session, then calculate the mean choice latency\n",
    "    choice_lat = df_raw.groupby(['Subject','Session'],as_index=False)['Choice_Lat'].mean()\n",
    "    \n",
    "    #add this information to the summary dataframe - same method as used above for premature responding\n",
    "    for num in np.sort(df_raw['Session'].unique()):\n",
    "        df_sum['collect_lat' + str(num)] = collect_lat.loc[collect_lat['Session']==num].set_index('Subject')['Collect_Lat']\n",
    "    for num in np.sort(df_raw['Session'].unique()):\n",
    "        df_sum['choice_lat' + str(num)] = choice_lat.loc[choice_lat['Session']==num].set_index('Subject')['Choice_Lat']\n",
    "        ###we're setting the index to subject, so why is ['Choice_Lat'] here?\n",
    "    return df_sum\n",
    "\n",
    "#let's run the function\n",
    "df_summary = get_latencies(df, df_summary)\n",
    "df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choice_lat = df.groupby(['Subject','Session'],as_index=False)['Choice_Lat'].mean()\n",
    "print(choice_lat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, we're almost done creating our summary dataframe. We only have two variables to go - omissions and trials completed\n",
    "\n",
    "These ones are straightforward - for omissions, we will simply count them (they're coded as a 1 in the raw dataframe, so we can just sum the column for each rat/session)\n",
    "\n",
    "For trials, we will take the max number in the trials column of the raw dataframe\n",
    "\n",
    "\n",
    "I'm going to put these two functions together, since they have the same structure as the functions above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_omit(df_raw,df_sum):\n",
    "    #group by subject and session and sum the 'omit' column\n",
    "    omit = df_raw.groupby(['Subject','Session'],as_index=False)['Omit'].sum() \n",
    "##takes the raw dataframe, groups by subject and session, and takes the sum of the \"Omit\" column \n",
    "    #append this information to the summary dataframe\n",
    "    for num in np.sort(df_raw['Session'].unique()): #gets all unique numbers in the session column\n",
    "        df_sum['omit' + str(num)] = omit.loc[omit['Session']==num].set_index('Subject')['Omit']\n",
    "    return df_sum\n",
    "\n",
    "def get_trials(df_raw,df_sum):\n",
    "    #group by subject and session and get the max number in the trial column\n",
    "    trials = df_raw.groupby(['Subject','Session'],as_index=False)['Trial'].max()\n",
    "    #append this information to the summary dataframe\n",
    "    for num in np.sort(df_raw['Session'].unique()):\n",
    "        df_sum['trial' + str(num)] = trials.loc[trials['Session']==num].set_index('Subject')['Trial']\n",
    "    return df_sum\n",
    "\n",
    "df_summary = get_omit(df, df_summary)\n",
    "df_summary = get_trials(df, df_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's look at our completed summary dataframe - yay!\n",
    "\n",
    "df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can also write a function that runs all the above functions to create the summary dataframe\n",
    "#I don't recommend running this because it will do what we already did, and is kind of slow haha\n",
    "# so it's just an FYI :)\n",
    "\n",
    "def get_summary_data(df_raw):\n",
    "    df_raw = get_choices(df_raw)\n",
    "    df_sum = get_sum_choice_all(df_raw)\n",
    "    df_sum = get_latencies(df_raw,df_sum)\n",
    "    df_sum = get_omit(df_raw,df_sum)\n",
    "    df_sum = get_trials(df_raw,df_sum)\n",
    "    df_sum = get_premature(df_raw,df_sum)\n",
    "    return df_sum\n",
    "\n",
    "df_summary = get_summary_data(df)\n",
    "# df_summary\n",
    "# get_summary_data(df)\n",
    "\n",
    "##this just does what we did earlier again, in one cell. No real point. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one more thing we can do - assign rats as risky or optimal, depending on their risk score\n",
    "\n",
    "def get_risk_status(df_sum, startsess, endsess):\n",
    "    #get risk status from specified sessions\n",
    "    #create lists for indexing based on risk status\n",
    "    risky = []\n",
    "    optimal = []\n",
    "    startsess = 'risk' + str(startsess)\n",
    "    endsess = 'risk' + str(endsess)\n",
    "    #calculate the mean risk score from the specified sessions\n",
    "    df_sum['mean_risk'] = df_sum.loc[:,startsess:endsess].mean(axis=1) ###did this create a 'mean_risk' column?\n",
    "    for sub in df_sum.index: #for each subject\n",
    "        if df_sum.at[sub,'mean_risk'] > 0: #if the mean risk for that subject is above zero\n",
    "            df_sum.at[sub,'risk_status'] = 1 #assign them a risk status of 1\n",
    "            optimal.append(sub) #and add them to the 'optimal' list\n",
    "        elif df_sum.at[sub,'mean_risk'] < 0: #if the mean risk for that subject is below zero\n",
    "            df_sum.at[sub,'risk_status'] = 2 #assign them a risk status of 2\n",
    "            risky.append(sub) #and append them to the 'risky' list\n",
    "    return df_sum, risky, optimal\n",
    "\n",
    "df_summary, risky, optimal = get_risk_status(df_summary, startsess, endsess) \n",
    "#remember, startsess and endsess were defined at the beginning of this script\n",
    "###what does it mean to assign comma separated objects?\n",
    "#### get_risk_status outputs 2 lists, and a dataframe *has to be same order as the return statement\n",
    "\n",
    "print(df_summary[['mean_risk','risk_status']]) ##printed 2 of many columns in df_summary\n",
    "print(risky, optimal)\n",
    "# print(df_summary) #--> huge table with mean_risk and risk_status at the rightmost edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one, two, three = 1,2,3\n",
    "one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok so now we have our beautiful summary dataframe! There are two things that we can do with this:\n",
    "\n",
    "1.) export the summary df to an excel file, which we can import into SPSS to run stats on. For this to be the most useful, we will also create a column that specifies whether the rat is in the control group or experimental group\n",
    "\n",
    "2.) calculate the means for the experimental group and the control group, to create figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''this function will save the dataframe as an excel file\n",
    "groups is a list of lists - i.e., a list of the control group list, and the experimental group list which we defined\n",
    "at the start of this script.\n",
    "groupname is the name of the column that will specify control vs experimental - in this case we want it to be\n",
    "transgene status (or tg_status for short)\n",
    "filename is the name of the exported excel sheet.\n",
    "'''\n",
    "def export_to_excel(df,groups,groupname,filename):\n",
    "    dfs = []\n",
    "    for group in groups: #this splits the dataframe by group\n",
    "        dfs.append(df.loc[group])\n",
    "    for i,df in enumerate(dfs): #this assigns a number to the tg_status column - in this case, 0 for control, 1 for experimental\n",
    "        df[groupname] = i ##i should be 0 and 1\n",
    "    df_export = pd.concat(dfs) #this recombines the dataframes\n",
    "    df_export.sort_index(inplace = True) #this sorts the subjects so they're in the right order after combining\n",
    "    df_export.to_excel(filename, index_label = 'Subject')\n",
    "\n",
    "#the filename I've chosen is BH07_free_S29-30 - same as the original filename except without 'raw', since it's summary data\n",
    "export_to_excel(df_summary, [control_group, exp_group], 'tg_status', 'BH07_free_S29-30.xlsx')\n",
    "\n",
    "#it should now be in your current working directory!\n",
    "##yes it is! Must view it in Excel\n",
    "###may want to change argument names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ok, let's create a dataframe that has the means for each variable for experimental vs control group\n",
    "#we'll also create a second dataframe that has the standard error of the means\n",
    "\n",
    "def get_group_means_sem(df_sum,groups, group_names):\n",
    "    dfs = []\n",
    "    #first split the dataframe based on experimental vs control\n",
    "    for group in groups:\n",
    "        dfs.append(df_sum.loc[group])\n",
    "    #create two dataframes - one for the means, one for the SEM\n",
    "    mean_scores = pd.DataFrame(columns=list(df_sum.columns))\n",
    "    stderror = pd.DataFrame(columns=mean_scores.columns)\n",
    "    #calculate the mean and standard errors, and store them in the above dataframes\n",
    "    for column in mean_scores.columns:\n",
    "        for i in range(len(groups)):\n",
    "            mean_scores.at[i,column] = dfs[i][column].mean()\n",
    "            stderror.at[i,column] = stats.sem(dfs[i][column])\n",
    "    #rename the rows to be the group_names (i.e., transgene positive and transgene negative)   \n",
    "    mean_scores.rename(index=group_names,inplace = True)\n",
    "    stderror.rename(index=group_names, inplace = True)\n",
    "    return mean_scores, stderror\n",
    "\n",
    "#for the renaming to work, group_names needs to be a dictionary\n",
    "group_names = {0: 'tg negative',\n",
    "              1: 'tg positive'}\n",
    "\n",
    "mean_scores, stderror = get_group_means_sem(df_summary, [control_group, exp_group], group_names)\n",
    "\n",
    "##control (tg negative) and experimental group should reflect dict \n",
    "\n",
    "mean_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we can create a figure! \n",
    "\n",
    "def rgt_plot(variable,startsess,endsess,group_names,title,scores,sem, highlight = None, var_title = None):\n",
    "    ##startsess and endsess allow us to clip the session data \n",
    "    if var_title == None:\n",
    "        var_title = variable\n",
    "    plt.rcParams.update({'font.size': 22})\n",
    "    fig,ax = plt.subplots(figsize = (20,10))\n",
    "    ax.set_ylabel(var_title)\n",
    "    ax.set_xlabel('Session')\n",
    "    ax.set_xlim(startsess,endsess)\n",
    "    ax.set_title(title + ': ' + var_title + '\\n' + 'Session ' + str(startsess) + '-' + str(endsess))\n",
    "    ax.spines['right'].set_linewidth(0)\n",
    "    ax.spines['top'].set_linewidth(0)\n",
    "    ax.spines['left'].set_linewidth(2)\n",
    "    ax.spines['bottom'].set_linewidth(2)\n",
    "    ax.set_xlim(startsess-.1,endsess+.1)\n",
    "    x=np.arange(startsess,endsess+1)\n",
    "    ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "   \n",
    "    for i,group in enumerate(group_names):\n",
    "        y = scores.loc[group,variable+str(startsess):variable+str(endsess)]\n",
    "        plt.errorbar(x, y,\n",
    "                     yerr = sem.loc[group,variable+str(startsess):variable+str(endsess)], \n",
    "                     label=group,linewidth=4, capsize = 8)\n",
    "    if highlight != None:\n",
    "        plt.axvline(highlight, 0, 1, color = 'gray', lw = 1)\n",
    "        ax.fill_between([highlight,endsess], ax.get_ylim()[0], ax.get_ylim()[1], facecolor='gray', alpha=0.2)\n",
    "    ax.legend()\n",
    "    \n",
    "rgt_plot('risk',startsess,endsess,['tg negative','tg positive'],title,mean_scores,stderror, var_title='risk score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choice_bar_plot(startsess, endsess, scores, sem,cmap = 'default'):\n",
    "    sess = list(range(startsess,endsess + 1))\n",
    "    labels = ['P1','P2','P3','P4']\n",
    "    df = pd.DataFrame()\n",
    "    df1 = pd.DataFrame()\n",
    "    if cmap == 'Paired':\n",
    "        colors = [plt.cm.Paired(5),plt.cm.Paired(1),plt.cm.Paired(4),plt.cm.Paired(0)]\n",
    "    if cmap == 'default':\n",
    "        colors = [plt.cm.Set1(1),plt.cm.Set1(0)]\n",
    "    for choice in labels:\n",
    "        df[choice] = scores.loc[:, [col for col in scores.columns if choice in col \n",
    "                                    and int(col[:col.index('P')]) in sess]].mean(axis = 1)\n",
    "        df1[choice] = sem.loc[:, [col for col in scores.columns if choice in col \n",
    "                                    and int(col[:col.index('P')]) in sess]].mean(axis = 1)\n",
    "    ax = df.transpose().plot.bar(rot = 0, yerr = df1.transpose(), capsize = 8, figsize = (20,8))\n",
    "    \n",
    "    # Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "    plt.rcParams.update({'font.size': 18})\n",
    "    ax.set_ylabel('% Choice', fontweight = 'bold', fontsize = 18)\n",
    "    ax.set_title('P1-P4 Choice', fontweight = 'bold', fontsize = 22, pad = 20)\n",
    "    ax.set_ylim(bottom = 0)\n",
    "    ax.spines['right'].set_linewidth(0)\n",
    "    ax.spines['top'].set_linewidth(0)\n",
    "    ax.spines['left'].set_linewidth(2)\n",
    "    ax.spines['bottom'].set_linewidth(2)\n",
    "    ax.legend()\n",
    "    \n",
    "choice_bar_plot(startsess,endsess,mean_scores,stderror)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
